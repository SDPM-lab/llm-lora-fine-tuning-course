{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ­Œè©å‰µä½œ AI - LoRA å¾®èª¿å¯¦æˆ°\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- æŒæ¡å–®ä¸€ä»»å‹™çš„ LoRA å¾®èª¿æµç¨‹\n",
    "- å­¸æœƒæº–å‚™è±å¯Œçš„æ­Œè©å‰µä½œæ•¸æ“š\n",
    "- å­¸æœƒä½¿ç”¨ LoRA ç­–ç•¥å¾®èª¿ LLM\n",
    "- å‰µå»º Gradio Web UI äº’å‹•ä»‹é¢\n",
    "\n",
    "## æ­Œè©å‰µä½œç‰¹è‰²\n",
    "- **å¤šå…ƒé¢¨æ ¼**ï¼šæµè¡Œã€æ°‘è¬ ã€æ–æ»¾ã€èªªå”±ç­‰\n",
    "- **æƒ…æ„Ÿè±å¯Œ**ï¼šæ„›æƒ…ã€å‹æƒ…ã€å‹µå¿—ã€æ‡·èˆŠç­‰\n",
    "- **çµæ§‹å®Œæ•´**ï¼šä¸»æ­Œã€å‰¯æ­Œã€æ©‹æ®µã€çµå°¾\n",
    "- **æŠ¼éŸ»å„ªç¾**ï¼šæ³¨é‡éŸ»è…³å’Œç¯€å¥æ„Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­ç½®èˆ‡å¥—ä»¶å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# å®‰è£å¿…è¦å¥—ä»¶\n",
    "!pip install -q torch transformers peft datasets accelerate bitsandbytes gradio\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import gradio as gr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"ğŸµ æ­Œè©å‰µä½œ AI è¨“ç·´ç’°å¢ƒ\")\n",
    "print(\"=\" * 40)\n",
    "print(\"ğŸ”¥ PyTorch ç‰ˆæœ¬:\", torch.__version__)\n",
    "print(\"ğŸ–¥ï¸  CUDA å¯ç”¨:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"ğŸ’¾ GPU è¨˜æ†¶é«”:\", f\"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"ğŸ·ï¸  GPU åç¨±:\", torch.cuda.get_device_name(0))\n",
    "print(\"ğŸ¤ Gradio ç‰ˆæœ¬:\", gr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ è¼‰å…¥æ ¸å¿ƒå¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model, \n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰æ ¸å¿ƒå¥—ä»¶è¼‰å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ è±å¯Œçš„æ­Œè©å‰µä½œè¨“ç·´æ•¸æ“š\n",
    "\n",
    "æˆ‘å€‘æº–å‚™äº† **20+ é¦–**ä¸åŒé¢¨æ ¼å’Œä¸»é¡Œçš„æ­Œè©ï¼Œæ¶µè“‹ï¼š\n",
    "- ğŸ¶ **æµè¡Œæƒ…æ­Œ**ï¼šæ„›æƒ…ä¸»é¡Œ\n",
    "- ğŸ¸ **æ–æ»¾å‹µå¿—**ï¼šå¥®é¬¥ä¸»é¡Œ\n",
    "- ğŸ¤ **æ°‘è¬ æ²»ç™’**ï¼šæº«æš–ä¸»é¡Œ\n",
    "- ğŸµ **èªªå”±ç¯€æ‹**ï¼šè¡—é ­æ–‡åŒ–\n",
    "- ğŸ¼ **å¤é¢¨è©©æ„**ï¼šä¸­åœ‹é¢¨\n",
    "- ğŸ¹ **çˆµå£«æµªæ¼«**ï¼šéƒ½å¸‚æƒ…èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è±å¯Œçš„æ­Œè©å‰µä½œè¨“ç·´æ•¸æ“šé›†\n",
    "lyrics_training_data = [\n",
    "    # ğŸ¶ æµè¡Œæƒ…æ­Œé¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–é—œæ–¼åˆæˆ€å›æ†¶çš„æµè¡Œæ­Œè©ï¼Œè¦æº«æŸ”ä¸”æ„Ÿäºº\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šåˆè¦‹æ™‚å…‰ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "é‚£å¹´å¤å¤©çš„åˆå¾Œ\n",
    "ä½ ç©¿è‘—ç™½è‰²æ´‹è£èµ°é\n",
    "é™½å…‰ç‘åœ¨ä½ é«®æ¢¢\n",
    "æˆ‘çš„å¿ƒè·³äº‚äº†ç¯€æ‹\n",
    "é’æ¾€çš„è©±èªèªªä¸å‡ºå£\n",
    "åªèƒ½å·å·çœ‹è‘—ä½ ç¬‘\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "åˆè¦‹æ™‚å…‰å¤šç¾å¥½\n",
    "ç´”çœŸæ­²æœˆä¸æœƒè€\n",
    "é›–ç„¶æˆ‘å€‘å·²åˆ†é–‹\n",
    "é‚£ä»½ç¾å¥½æ°¸é åœ¨\n",
    "åˆæˆ€å¦‚èŠ±èˆ¬ç¶»æ”¾\n",
    "åœ¨è¨˜æ†¶æ·±è™•é–ƒé–ƒç™¼äº®\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æ“å ´é‚Šçš„æ¢§æ¡æ¨¹\n",
    "è¦‹è­‰æˆ‘å€‘çš„é’æ˜¥æ­²æœˆ\n",
    "æ‰‹ç‰½æ‰‹èµ°éçš„è·¯\n",
    "ç¾åœ¨åªå‰©æˆ‘ä¸€å€‹äºº\n",
    "ç¿»é–‹èˆŠæ™‚çš„æ—¥è¨˜\n",
    "æ·šæ°´æ¨¡ç³Šäº†å­—è·¡\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "å¦‚æœèƒ½é‡ä¾†ä¸€æ¬¡\n",
    "æˆ‘æœƒå‹‡æ•¢èªªæ„›ä½ \n",
    "ä¸è®“éºæ†¾ç•™å¿ƒåº•\n",
    "è®“æ„›æƒ…æœ‰å€‹ç¾éº—çµå±€\n",
    "\n",
    "[çµå°¾]\n",
    "åˆè¦‹æ™‚å…‰å¤šç¾å¥½\n",
    "é‚£å€‹å¤å¤©æ°¸é›£å¿˜\n",
    "è¬è¬ä½ çµ¦æˆ‘çš„ç¾å¥½\n",
    "æ˜¯æˆ‘é’æ˜¥æœ€çè²´çš„å¯¶\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼é è·é›¢æˆ€æ„›çš„æ·±æƒ…æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šåƒé‡Œä¹‹å¤–ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "åŸå¸‚çš„å¤œç‡ˆé»äº®\n",
    "æˆ‘æœ›å‘ä½ çš„æ–¹å‘\n",
    "éš”è‘—åƒå±±è¬æ°´\n",
    "æ€å¿µå¦‚æ½®æ°´èˆ¬æ´¶æ¹§\n",
    "æ‰‹æ©Ÿè£¡çš„ä½ ç¬‘å¾—ç‡¦çˆ›\n",
    "è¢å¹•å»è§¸ç¢°ä¸åˆ°æº«æš–\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "åƒé‡Œä¹‹å¤–æœ‰å€‹ä½ \n",
    "æ˜¯æˆ‘å¿ƒä¸­æœ€ç¾çš„é¢¨æ™¯\n",
    "å°±ç®—ç›¸éš”å¤©æ¶¯æµ·è§’\n",
    "æ„›æ„ä¸æœƒå› è·é›¢è€Œæ¸›å°‘\n",
    "ç­‰åˆ°é‡é€¢çš„é‚£ä¸€å¤©\n",
    "æˆ‘è¦ç·Šç·ŠæŠŠä½ æ“æŠ±\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æ™‚å·®è®“æˆ‘å€‘éŒ¯é\n",
    "å¤ªå¤šæƒ³èªªçš„è©±èª\n",
    "ä½†æ¯ä¸€æ¬¡çš„é€šè©±\n",
    "éƒ½è®“å¿ƒæ›´åŠ é è¿‘\n",
    "æ”¶è—ä½ æ¯æ¢è¨Šæ¯\n",
    "åƒæ”¶è—çè²´çš„å¯¶çŸ³\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "é›–ç„¶ä¸èƒ½æ¯å¤©è¦‹é¢\n",
    "ä½†æˆ‘å€‘çš„å¿ƒåœ¨ä¸€èµ·\n",
    "æ„›æƒ…ä¸æœƒå› ç‚ºè·é›¢\n",
    "è€Œå¤±å»å®ƒçš„é­”åŠ›\n",
    "\n",
    "[çµå°¾]\n",
    "åƒé‡Œä¹‹å¤–æœ‰å€‹ä½ \n",
    "æ˜¯æˆ‘å‰é€²çš„å‹•åŠ›\n",
    "æ„›æƒ…è®“æˆ‘å€‘ç›¸ä¿¡\n",
    "è·é›¢åªæ˜¯æš«æ™‚çš„åˆ†é›¢\"\"\"\n",
    "    },\n",
    "    # ğŸ¸ æ–æ»¾å‹µå¿—é¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–å……æ»¿åŠ›é‡çš„æ–æ»¾å‹µå¿—æ­Œè©ï¼Œä¸»é¡Œæ˜¯è¿½æ±‚å¤¢æƒ³\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šä¸å±ˆçš„å¿ƒã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "é»‘å¤œç„¡æ³•ç†„æ»…æˆ‘çš„ç«ç„°\n",
    "æŒ«æŠ˜ç„¡æ³•æ‰“å€’æˆ‘çš„ä¿¡å¿µ\n",
    "å°±ç®—å…¨ä¸–ç•Œéƒ½èªªä¸å¯èƒ½\n",
    "æˆ‘ä¾ç„¶è¦è¿½é€æˆ‘çš„å¤¢\n",
    "è¡€æ¶²è£¡æµæ·Œè‘—ä¸å±ˆçš„éˆé­‚\n",
    "å¿ƒä¸­æœ‰åº§ä¸å€’çš„é«˜å±±\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æˆ‘æœ‰ä¸€é¡†ä¸å±ˆçš„å¿ƒ\n",
    "å†å¤§çš„é¢¨é›¨éƒ½ä¸æ€•\n",
    "å°±ç®—è·Œå€’ä¸€åƒæ¬¡\n",
    "æˆ‘æœƒç«™èµ·ä¾†ä¸€åƒé›¶ä¸€æ¬¡\n",
    "å¤¢æƒ³å°±æ˜¯æˆ‘çš„åŠ›é‡\n",
    "è®“æˆ‘å‹‡æ•¢åœ°å‘å‰é—–\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æ±—æ°´å’Œæ·šæ°´äº¤ç¹”æˆæ­Œ\n",
    "æ¯ä¸€æ»´éƒ½æ˜¯å¥®é¬¥çš„å°è¨˜\n",
    "åˆ¥äººçš„å˜²ç¬‘åªæ˜¯é›œéŸ³\n",
    "çœŸæ­£çš„å‹‡å£«å¾ä¸å›é ­\n",
    "èˆå°å°±åœ¨å‰æ–¹ç­‰å¾…\n",
    "æˆ‘è¦å”±å‡ºè‡ªå·±çš„ç²¾å½©\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "Rock and Rollç²¾ç¥åœ¨è¡€ç®¡è£¡å¥”é¨°\n",
    "è‡ªç”±çš„å‘¼å–Šéœ‡æ’¼å¤©ç©º\n",
    "æ²’æœ‰ä»€éº¼èƒ½é˜»æ“‹æˆ‘çš„è…³æ­¥\n",
    "å› ç‚ºæˆ‘å¿ƒä¸­æœ‰ä¸æ»…çš„ç«\n",
    "\n",
    "[çµå°¾]\n",
    "ä¸å±ˆçš„å¿ƒæ°¸é å¹´è¼•\n",
    "å¤¢æƒ³çš„è·¯æ°¸ä¸åœæ¯\n",
    "Let's rockï¼è®“æˆ‘å€‘æ–æ»¾ï¼\n",
    "ç”¨éŸ³æ¨‚é»ç‡ƒæ•´å€‹ä¸–ç•Œï¼\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼å…‹æœå›°é›£çš„æ–æ»¾æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šç ´ç¹­æˆè¶ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "è¢«å›°åœ¨é»‘æš—çš„ç¹­ä¸­\n",
    "æ„Ÿè¦ºä¸–ç•Œè¦æŠŠæˆ‘åæ²’\n",
    "æ¯ä¸€æ¬¡çš„æ™æ‰éƒ½æ˜¯ç—›\n",
    "ä½†æˆ‘ä¸æœƒé¸æ“‡æ”¾æ£„\n",
    "ç—›è‹¦æ˜¯æˆé•·çš„ä»£åƒ¹\n",
    "æˆ‘è¦ç”¨åŠ›é‡æ’•ç ´æŸç¸›\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æˆ‘è¦ç ´ç¹­æˆè¶\n",
    "é£›å‘è‡ªç”±çš„å¤©ç©º\n",
    "ä¸å†å®³æ€•é¢¨æš´\n",
    "å› ç‚ºæˆ‘å·²ç¶“è¶³å¤ å¼·å¤§\n",
    "ç ´ç¹­æˆè¶çš„é‚£ä¸€åˆ»\n",
    "å°±æ˜¯æˆ‘é‡ç”Ÿçš„æ™‚å€™\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æ›¾ç¶“çš„è»Ÿå¼±å·²æˆéå»\n",
    "ç¾åœ¨çš„æˆ‘ç„¡æ‰€ç•æ‡¼\n",
    "æ¯ä¸€é“å‚·ç–¤éƒ½æ˜¯å‹‡æ°£çš„è­‰æ˜\n",
    "æ¯ä¸€æ¬¡å¤±æ•—éƒ½è®“æˆ‘æ›´å …å¼·\n",
    "å‰ä»–çš„å’†å“®æ˜¯æˆ‘çš„æˆ°æ­Œ\n",
    "é¼“é»æ•²éŸ¿å‹åˆ©çš„ç¯€æ‹\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "è®ŠåŒ–æ˜¯ç—›è‹¦çš„\n",
    "ä½†ä¸è®Šæ˜¯æ­»äº¡çš„\n",
    "æˆ‘é¸æ“‡ç—›è‹¦åœ°æ´»è‘—\n",
    "ä¹Ÿä¸è¦å®‰é€¸åœ°æ­»å»\n",
    "\n",
    "[çµå°¾]\n",
    "çœ‹æˆ‘ç ´ç¹­è€Œå‡º\n",
    "å±•é–‹ç¾éº—çš„ç¿…è†€\n",
    "é€™å°±æ˜¯é‡ç”Ÿçš„åŠ›é‡\n",
    "é€™å°±æ˜¯ä¸æ­»çš„æ–æ»¾ç²¾ç¥ï¼\"\"\"\n",
    "    },\n",
    "    # ğŸ¤ æ°‘è¬ æ²»ç™’é¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–æº«æš–æ²»ç™’çš„æ°‘è¬ ï¼Œä¸»é¡Œæ˜¯é—œæ–¼å®¶çš„æº«æš–\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šå›å®¶çš„è·¯ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "èµ°éäº†å¤šå°‘æ¢è¡—\n",
    "çœ‹éäº†å¤šå°‘é¢¨æ™¯\n",
    "å¿ƒä¸­æœ€ç¾çš„é‚„æ˜¯\n",
    "é‚£æ¢å›å®¶çš„å°è·¯\n",
    "åª½åª½åœ¨å»šæˆ¿å¿™ç¢Œ\n",
    "çˆ¸çˆ¸åœ¨å®¢å»³çœ‹å ±\n",
    "ç°¡å–®çš„ç”Ÿæ´»ç‰‡æ®µ\n",
    "å»æ˜¯æœ€çè²´çš„å¯¶\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "å®¶æ˜¯æ°¸é çš„æ¸¯ç£\n",
    "ä¸ç®¡æˆ‘èµ°å¤šé \n",
    "é‚£ç›ç‚ºæˆ‘é»äº®çš„ç‡ˆ\n",
    "æŒ‡å¼•æˆ‘å›å®¶çš„æ–¹å‘\n",
    "å®¶äººçš„æ„›å¦‚æ˜¥é¢¨\n",
    "æº«æš–æˆ‘ç–²æ†Šçš„å¿ƒ\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "å¤–é¢çš„ä¸–ç•Œå¾ˆå¤§\n",
    "æˆ‘åƒè’²å…¬è‹±å››è™•é£„\n",
    "ä½†æ ¹æ°¸é åœ¨å®¶é„‰çš„åœŸåœ°è£¡\n",
    "é‚£è£¡æœ‰æˆ‘æœ€åˆçš„å¤¢\n",
    "å¥¶å¥¶çš„æ–æ¤…é‚„åœ¨æ–\n",
    "é™¢å­è£¡çš„æ¡‚èŠ±é‚„åœ¨é¦™\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "ç„¡è«–èµ°åˆ°å“ªè£¡\n",
    "æˆ‘éƒ½æ˜¯å®¶äººçš„å­©å­\n",
    "ç„¡è«–å¤šéº¼æˆåŠŸ\n",
    "å®¶æ°¸é æ˜¯æˆ‘çš„æ ¹\n",
    "\n",
    "[çµå°¾]\n",
    "å›å®¶çš„è·¯ä¸æœƒè®Š\n",
    "å®¶äººçš„æ„›ä¸æœƒè®Š\n",
    "é‚£æ˜¯æˆ‘å¿ƒä¸­æœ€æº«æš–çš„æ­Œ\n",
    "æ°¸é å”±ä¸å®Œçš„æ­Œ\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼å‹æƒ…é™ªä¼´çš„æ²»ç™’æ°‘è¬ \",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šè€æœ‹å‹ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "å’–å•¡åº—è£¡çš„ä¸‹åˆ\n",
    "æˆ‘å€‘ååœ¨è€ä½å­\n",
    "èŠè‘—å¤©å—æµ·åŒ—çš„è©±é¡Œ\n",
    "æ™‚é–“å½·å½¿åœæ­¢\n",
    "ä½ çš„ç¬‘è²é‚„æ˜¯é‚£æ¨£\n",
    "èƒ½æ²»ç™’æˆ‘æ‰€æœ‰çš„æ†‚å‚·\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "è€æœ‹å‹ï¼ŒçœŸå¥½\n",
    "æ­²æœˆæ²’æœ‰è®“æˆ‘å€‘ç–é›¢\n",
    "é›–ç„¶å„è‡ªéƒ½åœ¨å¥”è·‘\n",
    "å¿ƒé‚„æ˜¯é å¾—å¾ˆè¿‘\n",
    "è€æœ‹å‹çš„æº«æš–\n",
    "æ˜¯é€™ä¸–ç•Œæœ€ç¾çš„ç¦®ç‰©\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æƒ³èµ·æˆ‘å€‘ä¸€èµ·çš„æ—¥å­\n",
    "é’æ˜¥æ­²æœˆå¤šç¾å¥½\n",
    "ä¸€èµ·å“­éä¸€èµ·ç¬‘é\n",
    "ä¸€èµ·åšéçš„ç™½æ—¥å¤¢\n",
    "ç¾åœ¨æˆ‘å€‘éƒ½é•·å¤§äº†\n",
    "ä½†å‹èª¼ä¾ç„¶ç´”çœŸ\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "è¬è¬ä½ ä¸€ç›´åœ¨\n",
    "åœ¨æˆ‘éœ€è¦çš„æ™‚å€™\n",
    "è¬è¬ä½ çš„ç†è§£\n",
    "è®“æˆ‘ä¸å†å­¤å–®\n",
    "\n",
    "[çµå°¾]\n",
    "è€æœ‹å‹ï¼Œè€æœ‹å‹\n",
    "é¡˜æˆ‘å€‘éƒ½èƒ½å¥½å¥½çš„\n",
    "å‹æƒ…é€™é¦–æ­Œ\n",
    "æˆ‘å€‘è¦ä¸€ç›´å”±ä¸‹å»\"\"\"\n",
    "    },\n",
    "    # ğŸµ èªªå”±ç¯€æ‹é¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–èªªå”±æ­Œè©ï¼Œä¸»é¡Œæ˜¯é—œæ–¼åŸå¸‚ç”Ÿæ´»çš„å¥®é¬¥\",\n",
    "        \"output\": \"\"\"ğŸµ ã€ŠåŸå¸‚å¢æ—ã€‹\n",
    "\n",
    "[Verse 1]\n",
    "æ—©ä¸Šå…­é»é¬§é˜éŸ¿èµ·\n",
    "åˆæ˜¯ä¸€å¤©çš„æˆ°é¬¥é–‹å§‹\n",
    "åœ°éµè£¡äººæ½®æ“æ“ \n",
    "æ¯å€‹äººéƒ½åœ¨è¿½é€è‡ªå·±çš„å¤¢æƒ³\n",
    "è¾¦å…¬å¤§æ¨“åƒé«˜è³çš„ç›£ç„\n",
    "ä½†æˆ‘ä¸æœƒè¢«å›°ä½\n",
    "ç”¨èªªå”±ç•¶ä½œæ­¦å™¨\n",
    "åœ¨åŸå¸‚å¢æ—è£¡é—–å‡ºä¸€æ¢è·¯\n",
    "\n",
    "[Hook]\n",
    "City life, city dreams\n",
    "åœ¨é‹¼ç­‹æ°´æ³¥ä¸­å°‹æ‰¾è‡ªå·±\n",
    "Hustle hard, never stop\n",
    "ç›´åˆ°æˆåŠŸç«™åœ¨é ‚å³°\n",
    "é€™æ˜¯åŸå¸‚å¢æ—çš„æ³•å‰‡\n",
    "é©è€…ç”Ÿå­˜å¼±è€…æ·˜æ±°\n",
    "\n",
    "[Verse 2]\n",
    "å¤œæ™šçš„éœ“è™¹ç‡ˆé–ƒçˆ\n",
    "ç…§äº®æˆ‘å‰é€²çš„é“è·¯\n",
    "è¡—é ­å··å°¾çš„æ•…äº‹\n",
    "éƒ½å¯«é€²æˆ‘çš„rapè£¡\n",
    "å¾åº•å±¤é–‹å§‹çˆ¬èµ·\n",
    "æ¯ä¸€æ­¥éƒ½è¸å¾—å¾ˆå¯¦\n",
    "ä¸é é—œä¿‚ä¸èµ°æ·å¾‘\n",
    "ç”¨å¯¦åŠ›è­‰æ˜è‡ªå·±\n",
    "\n",
    "[Bridge]\n",
    "é€™åº§åŸå¸‚ä¸ç›¸ä¿¡çœ¼æ·š\n",
    "åªç›¸ä¿¡æ±—æ°´å’ŒåŠªåŠ›\n",
    "æ¯å€‹äººéƒ½æœ‰æ©Ÿæœƒ\n",
    "é—œéµçœ‹ä½ æ•¢ä¸æ•¢æ‹¼\n",
    "\n",
    "[Outro]\n",
    "From the bottom to the top\n",
    "æˆ‘çš„æ•…äº‹æ°¸ä¸åœ\n",
    "åŸå¸‚å¢æ—è¦‹è­‰æˆ‘çš„æˆé•·\n",
    "é€™å°±æ˜¯æˆ‘çš„hip-hop!\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼é’æ˜¥å›æ†¶çš„èªªå”±æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šå°‘å¹´æ™‚ä»£ã€‹\n",
    "\n",
    "[Verse 1]\n",
    "é‚„è¨˜å¾—é‚£äº›å¹´æˆ‘å€‘ä¸€èµ·ç˜‹\n",
    "åœ¨çƒå ´ä¸Šæ®ç‘é’æ˜¥çš„æ±—\n",
    "æ”¾å­¸å¾Œçš„éŠæˆ²å»³\n",
    "é€±æœ«çš„KTV\n",
    "é‚£æ™‚å€™çš„æˆ‘å€‘ä»¥ç‚ºæ™‚é–“å¾ˆå¤š\n",
    "ä»¥ç‚ºå‹æƒ…æœƒæ°¸é ä¸è®Š\n",
    "ç¾åœ¨å„è‡ªå¥”å‘ä¸åŒçš„æ–¹å‘\n",
    "ä½†è¨˜æ†¶æ°¸é é®®æ´»\n",
    "\n",
    "[Hook]\n",
    "å°‘å¹´æ™‚ä»£ä¸æœƒå†ä¾†\n",
    "ä½†é‚£äº›å›æ†¶æ°¸é ç²¾å½©\n",
    "We were young and free\n",
    "æ²’æœ‰ä»€éº¼å¥½æ“”å¿ƒ\n",
    "é‚£æ˜¯æœ€ç¾å¥½çš„å¹´ä»£\n",
    "ç„¡æ†‚ç„¡æ…®çš„å¹´ä»£\n",
    "\n",
    "[Verse 2]\n",
    "åˆæˆ€çš„é…¸ç”œè‹¦è¾£\n",
    "è€ƒè©¦å‰çš„ç·Šå¼µç„¦æ…®\n",
    "ç•¢æ¥­å…¸ç¦®çš„çœ¼æ·š\n",
    "éƒ½æ˜¯é’æ˜¥çš„å°è¨˜\n",
    "é‚£æ™‚å€™è¦ºå¾—å¤§äººå¾ˆç…©\n",
    "ç¾åœ¨æ‰çŸ¥é“ä»–å€‘çš„ç”¨å¿ƒ\n",
    "é‚£æ™‚å€™æ€¥è‘—é•·å¤§\n",
    "ç¾åœ¨æƒ³å›åˆ°éå»\n",
    "\n",
    "[Bridge]\n",
    "æ™‚å…‰æ©Ÿå¦‚æœçœŸçš„å­˜åœ¨\n",
    "æˆ‘æƒ³å›åˆ°é‚£å€‹å¤å¤©\n",
    "å†éä¸€æ¬¡å°‘å¹´æ™‚ä»£\n",
    "å†æ„Ÿå—ä¸€æ¬¡é‚£ä»½ç´”çœŸ\n",
    "\n",
    "[Outro]\n",
    "Youth is gone but not forgotten\n",
    "é’æ˜¥ä¸è€ï¼Œå›æ†¶æ°¸æ†\n",
    "é€™å°±æ˜¯æˆ‘å€‘çš„æ•…äº‹\n",
    "é€™å°±æ˜¯æˆ‘å€‘çš„é’æ˜¥rap!\"\"\"\n",
    "    },\n",
    "    # ğŸ¼ å¤é¢¨è©©æ„é¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–ä¸­åœ‹é¢¨å¤éŸ»æ­Œè©ï¼Œä¸»é¡Œæ˜¯æ±Ÿå—æ°´é„‰\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šæ±Ÿå—ç…™é›¨ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "å°æ©‹æµæ°´ç¹äººå®¶\n",
    "é’çŸ³æ¿è·¯æ˜ æ™šéœ\n",
    "çƒŸé›¨æœ¦æœ§æ±Ÿå—æ™¯\n",
    "å¦‚è©©å¦‚ç•«å…¥æˆ‘å¿ƒ\n",
    "æ’ä¸€æŠŠæ²¹ç´™å‚˜\n",
    "èµ°éé’ç£šç™½ç“¦é–“\n",
    "è½é›¨æ»´ç­”æ»´ç­”éŸ¿\n",
    "å½·å½¿å¤äººåœ¨åŸå”±\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æ±Ÿå—å¥½é¢¨å…‰\n",
    "æœ€æ†¶æ˜¯æ˜¥æ±Ÿ\n",
    "æ¥ŠæŸ³ç¶ å¦‚ç…™\n",
    "æ¡ƒèŠ±ç´…ä¼¼éœ\n",
    "ä¸€å£ºè€é…’é†‰æ–œé™½\n",
    "åŠå·è©©æ›¸è©±æµå¹´\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "è¥¿æ¹–é‚ŠæŸ³çµ²é£„æš\n",
    "è˜‡å ¤ä¸ŠéŠäººå¦‚ç¹”\n",
    "æ–·æ©‹æ®˜é›ªè©±æ·’ç¾\n",
    "é›·å³°å¡”ä¸‹è¨´æƒ…é•·\n",
    "çƒç¯·èˆ¹æ–å‘é æ–¹\n",
    "æ¼æ­Œæ™šå”±èµ·å¤•é™½\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "åƒå¹´å¤éŸ»çŒ¶åœ¨\n",
    "æ–‡äººå¢¨å®¢ç•™é¦™\n",
    "æ±Ÿå—å¦‚ä¸€å¹…ç•«\n",
    "æ°¸é çœ‹ä¸å¤ çš„ç¾\n",
    "\n",
    "[çµå°¾]\n",
    "æ±Ÿå—ç…™é›¨å¤¢ä¸­ä¾†\n",
    "é†’ä¾†å·²æ˜¯å®¢ä»–é„‰\n",
    "ä½•æ™‚èƒ½å†å›æ±Ÿå—\n",
    "é‡æº«é‚£æ®µå¥½æ™‚å…‰\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼å¤ä»£ä¿ å®¢çš„ä¸­åœ‹é¢¨æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šä¿ å®¢è¡Œã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "ä»—åŠèµ°å¤©æ¶¯\n",
    "å¿«æ„æ±Ÿæ¹–è·¯\n",
    "åæ­¥æ®ºä¸€äºº\n",
    "åƒé‡Œä¸ç•™å\n",
    "ç™½è¡£å¦‚é›ªåŠå¦‚éœœ\n",
    "ä¿ éª¨æŸ”æƒ…å¿ƒå¦‚éµ\n",
    "ç‚ºåœ‹ç‚ºæ°‘é™¤æš´å®‰è‰¯\n",
    "ç”Ÿæ­»çœ‹æ·¡ç¾©å­—ç•¶å…ˆ\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "ä¿ å®¢ä¸å•å‡ºè™•\n",
    "åªçœ‹æ­£ç¾©åœ¨å¿ƒ\n",
    "åˆ€å…‰åŠå½±ä¸­\n",
    "å®ˆè­·è’¼ç”Ÿå®‰å¯§\n",
    "ç¸±æ©«å¤©ä¸‹ç„¡æ•µæ‰‹\n",
    "ç¬‘å‚²æ±Ÿæ¹–çœŸè‹±é›„\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æœˆä¸‹ç¨é…Œä¸€å£ºé…’\n",
    "å›æƒ³ç•¶å¹´å°‘å¹´ç‹‚\n",
    "å¸«çˆ¶æ•™å°çŒ¶åœ¨è€³\n",
    "ä¿ ä¹‹å¤§è€…ç‚ºåœ‹ç‚ºæ°‘\n",
    "é›–æœ‰ç„¡æ•¸ä»‡æ•µè¿½æ®º\n",
    "ä½†ä¿ ç¾©ä¹‹å¿ƒæ°¸ä¸æ”¹\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "æ±Ÿæ¹–éšªæƒ¡äººå¿ƒè¤‡é›œ\n",
    "ä½†ç¸½æœ‰äººé¡˜æ„å®ˆè­·å…‰æ˜\n",
    "é€™å°±æ˜¯ä¿ å®¢çš„ä½¿å‘½\n",
    "é€™å°±æ˜¯ä¿ å®¢çš„å®¿å‘½\n",
    "\n",
    "[çµå°¾]\n",
    "ä¿ å®¢è¡Œï¼Œä¿ å®¢è¡Œ\n",
    "ä»—åŠå¤©æ¶¯æ°¸ä¸åœ\n",
    "åªè¦äººé–“æœ‰ä¸å¹³\n",
    "ä¿ å®¢ç²¾ç¥æ°¸æµå‚³\"\"\"\n",
    "    },\n",
    "    # ğŸ¹ çˆµå£«æµªæ¼«é¡\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–çˆµå£«é¢¨æ ¼çš„æµªæ¼«æ­Œè©ï¼Œå ´æ™¯æ˜¯åˆå¤œçš„åŸå¸‚\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šåˆå¤œè—èª¿ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "åˆå¤œçš„åŸå¸‚ç‡ˆç«é—ŒçŠ\n",
    "çˆµå£«é…’å§è£¡è–©å…‹æ–¯é¢¨è¼•éŸ¿\n",
    "ä½ ååœ¨å§å°é‚Šæ·ºé…Œç´…é…’\n",
    "ç¾å¾—åƒå¹…æ²¹ç•«\n",
    "é‹¼ç´å¸«å½ˆè‘—è—èª¿\n",
    "è¨´èªªè‘—å¤œçš„æ•…äº‹\n",
    "è€Œæˆ‘åªæƒ³é è¿‘ä½ \n",
    "åœ¨é€™å€‹è¿·äººçš„å¤œæ™š\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "Midnight blues\n",
    "è®“æˆ‘ç‚ºä½ å”±ä¸€é¦–æ­Œ\n",
    "City lights\n",
    "è¦‹è­‰æˆ‘å€‘çš„é‚‚é€…\n",
    "åœ¨é€™å€‹å……æ»¿çˆµå£«æ¨‚çš„å¤œæ™š\n",
    "è®“æˆ‘å€‘æ…¢æ…¢ç›¸æ„›\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "ä½ çš„çœ¼ç¥å¦‚æ˜Ÿå…‰èˆ¬é–ƒçˆ\n",
    "åœ¨éœ“è™¹ç‡ˆçš„æ˜ è¥¯ä¸‹\n",
    "é¡¯å¾—æ ¼å¤–è¿·äºº\n",
    "ä½éŸ³æç´çš„æ—‹å¾‹\n",
    "åƒä½ èµ°è·¯çš„ç¯€æ‹\n",
    "å„ªé›…è€Œå……æ»¿èª˜æƒ‘\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "Dance with me under the moonlight\n",
    "åœ¨æœˆå…‰ä¸‹èˆ‡æˆ‘å…±èˆ\n",
    "Let the jazz music guide our hearts\n",
    "è®“çˆµå£«æ¨‚æŒ‡å¼•æˆ‘å€‘çš„å¿ƒ\n",
    "\n",
    "[çµå°¾]\n",
    "åˆå¤œè—èª¿é‚„åœ¨ç¹¼çºŒ\n",
    "ä½†æˆ‘å·²ç¶“æ„›ä¸Šäº†ä½ \n",
    "This is our midnight story\n",
    "é€™æ˜¯æˆ‘å€‘çš„åˆå¤œæ•…äº‹\"\"\"\n",
    "    },\n",
    "    # ğŸ¶ æ›´å¤šæµè¡Œæƒ…æ­Œ\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼å¤±æˆ€å¾Œé‡æ–°é–‹å§‹çš„å‹µå¿—æƒ…æ­Œ\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šé‡æ–°é–‹å§‹ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "æ”¶æ‹¾å¥½ç ´ç¢çš„å¿ƒæƒ…\n",
    "æŠŠçœ¼æ·šæ“¦ä¹¾æ·¨\n",
    "é›–ç„¶ä½ å·²ç¶“é›¢é–‹\n",
    "ä½†æˆ‘è¦ç¹¼çºŒå‰é€²\n",
    "æ„›æƒ…ä¸æ˜¯ç”Ÿå‘½çš„å…¨éƒ¨\n",
    "æˆ‘é‚„æœ‰å¾ˆå¤šå¤¢æƒ³è¦å®Œæˆ\n",
    "æ„Ÿè¬ä½ çµ¦æˆ‘çš„å›æ†¶\n",
    "ç¾åœ¨æˆ‘è¦å­¸æœƒæ”¾æ‰‹\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æˆ‘è¦é‡æ–°é–‹å§‹\n",
    "é‡æ–°æ„›è‡ªå·±\n",
    "ä¸å†ç‚ºäº†èª°è€Œå“­æ³£\n",
    "ä¸å†ç‚ºäº†èª°è€Œè¿·å¤±\n",
    "é‡æ–°é–‹å§‹çš„æˆ‘\n",
    "æœƒè®Šå¾—æ›´åŠ ç¾éº—\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "åˆªæ‰æ‰€æœ‰ä½ çš„ç…§ç‰‡\n",
    "æ”¶èµ·æ‰€æœ‰çš„å›æ†¶\n",
    "ä¸æ˜¯å› ç‚ºä¸æ„›äº†\n",
    "è€Œæ˜¯å­¸æœƒäº†æ„›è‡ªå·±\n",
    "ä¸–ç•Œé‚„æ˜¯å¾ˆç¾å¥½\n",
    "å¤ªé™½ä¾ç„¶æœƒå‡èµ·\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "æ„Ÿè¬é‚£æ®µç¾å¥½çš„æ™‚å…‰\n",
    "æ•™æœƒæˆ‘å¦‚ä½•å»æ„›\n",
    "ç¾åœ¨æˆ‘è¦ç”¨é€™ä»½æ„›\n",
    "å¥½å¥½æ„›è‡ªå·±\n",
    "\n",
    "[çµå°¾]\n",
    "é‡æ–°é–‹å§‹ä¸æ˜¯çµæŸ\n",
    "è€Œæ˜¯å¦ä¸€å€‹é–‹å§‹\n",
    "æˆ‘ç›¸ä¿¡æœªä¾†æœƒæ›´å¥½\n",
    "å› ç‚ºæˆ‘å·²ç¶“å­¸æœƒå …å¼·\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–é—œæ–¼æ¯è¦ªç¯€çš„æ„Ÿæ©æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šåª½åª½çš„æ„›ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "å°æ™‚å€™ç¸½æ˜¯ä¸æ‡‚äº‹\n",
    "è®“åª½åª½ç‚ºæˆ‘æ“ç¢å¿ƒ\n",
    "æ·±å¤œè£¡å¥¹ç‚ºæˆ‘è“‹è¢«å­\n",
    "ç”Ÿç—…æ™‚å¥¹å¾¹å¤œä¸çœ \n",
    "é‚£é›™ç²—ç³™çš„æ‰‹\n",
    "ç‚ºæˆ‘åšéå¤šå°‘äº‹\n",
    "é‚£æº«æš–çš„æ‡·æŠ±\n",
    "æ˜¯æˆ‘æœ€å®‰å…¨çš„æ¸¯ç£\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "åª½åª½çš„æ„›åƒæµ·ä¸€æ¨£æ·±\n",
    "åŒ…å®¹æˆ‘æ‰€æœ‰çš„ä»»æ€§\n",
    "åª½åª½çš„æ„›åƒå±±ä¸€æ¨£é«˜\n",
    "çµ¦æˆ‘ç„¡çª®çš„åŠ›é‡\n",
    "è¬è¬æ‚¨çµ¦äº†æˆ‘ç”Ÿå‘½\n",
    "è¬è¬æ‚¨çµ¦äº†æˆ‘æ„›\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "é•·å¤§å¾Œæ‰æ˜ç™½\n",
    "åª½åª½æœ‰å¤šä¸å®¹æ˜“\n",
    "ç‚ºäº†æˆ‘å¥¹æ”¾æ£„äº†å¤¢æƒ³\n",
    "æŠŠæ‰€æœ‰çš„æ„›éƒ½çµ¦äº†æˆ‘\n",
    "ç¾åœ¨å¥¹é ­é«®ç™½äº†\n",
    "è‡‰ä¸Šçšºç´‹å¤šäº†\n",
    "ä½†åœ¨æˆ‘å¿ƒä¸­\n",
    "å¥¹æ°¸é æœ€ç¾\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "ç¾åœ¨æ›æˆ‘ä¾†æ„›æ‚¨\n",
    "ç”¨æˆ‘å…¨éƒ¨çš„å¿ƒ\n",
    "å°±åƒæ‚¨æ„›æˆ‘ä¸€æ¨£\n",
    "ç„¡ç§è€Œæ·±æ²‰\n",
    "\n",
    "[çµå°¾]\n",
    "åª½åª½æˆ‘æ„›æ‚¨\n",
    "é€™è¼©å­éƒ½ä¸æœƒè®Š\n",
    "æ‚¨æ˜¯æˆ‘æœ€é‡è¦çš„äºº\n",
    "æˆ‘æ°¸é çš„åª½åª½\"\"\"\n",
    "    },\n",
    "    # ğŸ¸ æ›´å¤šæ–æ»¾å‹µå¿—\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼é’å¹´å‰µæ¥­å¥®é¬¥çš„æ–æ»¾æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šå‰µæ¥­è€…ä¹‹æ­Œã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "èƒŒè‘—èƒŒåŒ…èµ°å‡ºæ ¡é–€\n",
    "å¿ƒä¸­ç‡ƒç‡’è‘—å‰µæ¥­å¤¢\n",
    "æ²’æœ‰è³‡é‡‘æ²’æœ‰äººè„ˆ\n",
    "åªæœ‰æ»¿è…”çš„ç†±è¡€\n",
    "åœ¨å°å°çš„è»Šåº«è£¡\n",
    "é–‹å§‹æˆ‘çš„ç¬¬ä¸€æ­¥\n",
    "é›–ç„¶æ¢ä»¶å¾ˆè‰±è‹¦\n",
    "ä½†å¤¢æƒ³è®“æˆ‘å …å¼·\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æˆ‘æ˜¯å‰µæ¥­è€…\n",
    "ä¸æ€•å¤±æ•—ä¸æ€•ç´¯\n",
    "å°±ç®—è·Œå€’äº†\n",
    "ä¹Ÿè¦çˆ¬èµ·ä¾†ç¹¼çºŒé£›\n",
    "æ”¹è®Šä¸–ç•Œçš„å¤¢æƒ³\n",
    "åœ¨æˆ‘å¿ƒä¸­ç‡ƒç‡’\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "ç†¬å¤œå¯«ä»£ç¢¼\n",
    "å–å’–å•¡ç•¶æ™šé¤\n",
    "ç‚ºäº†ä¸€å€‹bug\n",
    "å¯ä»¥å»¢å¯¢å¿˜é£Ÿ\n",
    "æŠ•è³‡äººçš„æ‹’çµ•\n",
    "ä¸èƒ½æ¾†æ»…æˆ‘çš„ç«\n",
    "ç”¨æˆ¶çš„èªå¯\n",
    "æ˜¯æœ€å¤§çš„çå‹µ\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "Every failure is a lesson\n",
    "æ¯æ¬¡å¤±æ•—éƒ½æ˜¯å­¸ç¿’\n",
    "Every setback makes us stronger\n",
    "æ¯æ¬¡æŒ«æŠ˜è®“æˆ‘å€‘æ›´å¼·\n",
    "\n",
    "[çµå°¾]\n",
    "å‰µæ¥­è·¯ä¸Šä¸å­¤å–®\n",
    "å› ç‚ºæœ‰å¤¢æƒ³ç›¸ä¼´\n",
    "ç¸½æœ‰ä¸€å¤©æˆ‘å€‘æœƒæˆåŠŸ\n",
    "ç”¨è¡Œå‹•è­‰æ˜é’æ˜¥ç„¡æ•µï¼\"\"\"\n",
    "    },\n",
    "    # ğŸ¤ æ›´å¤šæ°‘è¬ æ²»ç™’\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–é—œæ–¼å››å­£è®ŠåŒ–çš„æº«æš–æ°‘è¬ \",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šå››å­£æ­Œã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ - æ˜¥å¤©]\n",
    "æ˜¥å¤©ä¾†äº†èŠ±å…’é–‹\n",
    "è¬ç‰©å¾©ç”¦å¤§åœ°ç¶ \n",
    "ç‡•å­å¾å—æ–¹é£›å›ä¾†\n",
    "å¸¶ä¾†æº«æš–çš„æ¶ˆæ¯\n",
    "æˆ‘å€‘è„«ä¸‹åšé‡çš„å¤–å¥—\n",
    "æ„Ÿå—æ˜¥é¢¨çš„æº«æŸ”\n",
    "\n",
    "[ç¬¬äºŒæ®µ - å¤å¤©]\n",
    "å¤å¤©çš„é™½å…‰ç†±æƒ…å¦‚ç«\n",
    "èŸ¬é³´è²è²å…¥è€³ä¾†\n",
    "å†°é®è¥¿ç“œç”œå¦‚èœœ\n",
    "å¤å¤œæ™šé¢¨è¼•è¼•å¹\n",
    "å’Œæœ‹å‹ä¸€èµ·çœ‹æ˜Ÿæ˜Ÿ\n",
    "è¨±ä¸‹å¤æ—¥çš„å¿ƒé¡˜\n",
    "\n",
    "[ç¬¬ä¸‰æ®µ - ç§‹å¤©]\n",
    "ç§‹å¤©çš„è‘‰å­é»ƒäº†\n",
    "è±æ”¶çš„å­£ç¯€åˆ°äº†\n",
    "æ¡‚èŠ±é¦™é£„åƒé‡Œå¤–\n",
    "æœˆé¤…åœ“åœ“äººåœ˜åœ“\n",
    "ç©¿ä¸Šæº«æš–çš„æ¯›è¡£\n",
    "æ„Ÿå—ç§‹æ—¥çš„è©©æ„\n",
    "\n",
    "[ç¬¬å››æ®µ - å†¬å¤©]\n",
    "å†¬å¤©é›ªèŠ±é£„é£„\n",
    "ä¸–ç•Œè®Šæˆç™½è‰²ç«¥è©±\n",
    "åœçˆå–æš–è©±å®¶å¸¸\n",
    "ä¸€å¹´åˆè¦éå»äº†\n",
    "æ„Ÿè¬å››å­£çš„é™ªä¼´\n",
    "æœŸå¾…ä¾†å¹´æ›´ç¾å¥½\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "å››å­£è¼ªè¿´æ°¸ä¸åœ\n",
    "æ¯å€‹å­£ç¯€éƒ½ç¾éº—\n",
    "å°±åƒäººç”Ÿçš„è·¯\n",
    "æœ‰èµ·æœ‰è½æ‰å®Œæ•´\n",
    "æ„Ÿè¬æ™‚å…‰çš„ç¦®ç‰©\n",
    "æ„Ÿè¬ç”Ÿå‘½çš„å¥‡è·¡\n",
    "\n",
    "[çµå°¾]\n",
    "æ˜¥å¤ç§‹å†¬æˆ‘éƒ½æ„›\n",
    "å› ç‚ºæ¯å€‹å­£ç¯€\n",
    "éƒ½æœ‰å®ƒç¨ç‰¹çš„ç¾\n",
    "éƒ½å€¼å¾—æˆ‘å€‘çæƒœ\"\"\"\n",
    "    },\n",
    "    # ğŸµ æ›´å¤šèªªå”±é¢¨æ ¼\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼ç¶²çµ¡æ™‚ä»£çš„èªªå”±æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€ŠDigital Ageã€‹\n",
    "\n",
    "[Verse 1]\n",
    "Wake up check my phoneç¬¬ä¸€ä»¶äº‹\n",
    "ç¤¾äº¤åª’é«”ä¸Šçš„æ¶ˆæ¯ä¸åœ\n",
    "é»è®šè©•è«–è½‰ç™¼åˆ†äº«\n",
    "è™›æ“¬ä¸–ç•Œè£¡æ‰¾å­˜åœ¨æ„Ÿ\n",
    "WiFiæ–·äº†åƒæ–·äº†ç¿…è†€\n",
    "5Gæ™‚ä»£é€Ÿåº¦é£›å¿«\n",
    "ä½†æœ‰æ™‚å€™æˆ‘ä¹Ÿæƒ³\n",
    "å›åˆ°æ²’æœ‰æ‰‹æ©Ÿçš„å¹´ä»£\n",
    "\n",
    "[Hook]\n",
    "Digital age we're living in\n",
    "æ•¸å­—æ™‚ä»£æ”¹è®Šä¸€åˆ‡\n",
    "Connect the world but disconnect ourselves\n",
    "é€£æ¥ä¸–ç•Œå»å¤±å»è‡ªå·±\n",
    "This is the reality\n",
    "é€™å°±æ˜¯ç¾å¯¦\n",
    "\n",
    "[Verse 2]\n",
    "ç·šä¸Šè³¼ç‰©ç·šä¸Šå­¸ç¿’\n",
    "ç·šä¸Šå·¥ä½œç·šä¸Šç¤¾äº¤\n",
    "AIäººå·¥æ™ºèƒ½å´›èµ·\n",
    "æ©Ÿå™¨äººé–‹å§‹æ€è€ƒ\n",
    "å¤§æ•¸æ“šåˆ†ææˆ‘å€‘çš„è¡Œç‚º\n",
    "æ¼”ç®—æ³•æ±ºå®šæˆ‘å€‘çœ‹ä»€éº¼\n",
    "éš±ç§åœ¨é€æ˜çš„ä¸–ç•Œè£¡\n",
    "è®Šå¾—è¶Šä¾†è¶Šçè²´\n",
    "\n",
    "[Bridge]\n",
    "Technology is a double-edged sword\n",
    "ç§‘æŠ€æ˜¯æŠŠé›™åˆƒåŠ\n",
    "We need to learn how to use it right\n",
    "æˆ‘å€‘éœ€è¦å­¸æœƒæ­£ç¢ºä½¿ç”¨\n",
    "\n",
    "[Outro]\n",
    "Digital natives that's what we are\n",
    "æˆ‘å€‘æ˜¯æ•¸å­—åŸä½æ°‘\n",
    "But don't forget the human heart\n",
    "ä½†åˆ¥å¿˜äº†äººé¡çš„å¿ƒ\n",
    "åœ¨é€™å€‹æ•¸ä½æ™‚ä»£è£¡\n",
    "ä¿æŒäººæ€§æœ€é‡è¦ï¼\"\"\"\n",
    "    },\n",
    "    # ğŸ¼ æ›´å¤šå¤é¢¨è©©æ„\n",
    "    {\n",
    "        \"instruction\": \"å¯«ä¸€é¦–é—œæ–¼å¤ä»£æ›¸ç”Ÿæ±‚å­¸çš„ä¸­åœ‹é¢¨æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šæ›¸ç”ŸåŸã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "åå¹´å¯’çª—è‹¦è®€æ›¸\n",
    "åªç‚ºä¸€æœç™»é‡‘æ¦œ\n",
    "é’ç‡ˆé»ƒå·ä¼´é•·å¤œ\n",
    "è©©æ›¸æ»¿è…¹å¿—é«˜é \n",
    "æ¢…èŠ±é¦™è‡ªè‹¦å¯’ä¾†\n",
    "å¯¶åŠé‹’å¾ç£¨ç¤ªå‡º\n",
    "é›–ç„¶å‰è·¯å¤šåå·\n",
    "æ›¸ç”Ÿæ„æ°£ä¸èƒ½æ”¹\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "æ›¸ä¸­è‡ªæœ‰é»ƒé‡‘å±‹\n",
    "æ›¸ä¸­è‡ªæœ‰é¡å¦‚ç‰\n",
    "ä½†æ±‚å­¸è€Œæ™‚ç¿’ä¹‹\n",
    "ä¸äº¦èªªä¹ä¸äº¦æ¨‚ä¹\n",
    "ä¿®èº«é½Šå®¶æ²»åœ‹å¹³å¤©ä¸‹\n",
    "é€™æ˜¯æ›¸ç”Ÿçš„æŠ±è² \n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "æ˜¥é¢¨å¾—æ„é¦¬è¹„ç–¾\n",
    "ä¸€æ—¥çœ‹ç›¡é•·å®‰èŠ±\n",
    "é‡‘æ¦œé¡Œåæ™‚\n",
    "å–œæ‚…å¦‚æ½®æ¹§\n",
    "ä½†æ›´é‡è¦çš„æ˜¯\n",
    "å­¸ä»¥è‡´ç”¨æ¿Ÿè’¼ç”Ÿ\n",
    "ä¸è² å¯’çª—è‹¦è®€æ™‚\n",
    "ä¸è² è–è³¢æ•™èª¨æ©\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "å­¸è€Œä¸æ€å‰‡ç½”\n",
    "æ€è€Œä¸å­¸å‰‡æ®†\n",
    "çŸ¥ä¹‹ç‚ºçŸ¥ä¹‹\n",
    "ä¸çŸ¥ç‚ºä¸çŸ¥\n",
    "\n",
    "[çµå°¾]\n",
    "æ›¸ç”Ÿæ„æ°£æ°¸ä¸è€\n",
    "å­¸ç„¡æ­¢å¢ƒè·¯æ¼«æ¼«\n",
    "ç¸±ç„¶ç™½é«®æ»¿é ­\n",
    "æ±‚å­¸ä¹‹å¿ƒä¸è®Š\"\"\"\n",
    "    },\n",
    "    # ğŸ¹ æ›´å¤šçˆµå£«æµªæ¼«\n",
    "    {\n",
    "        \"instruction\": \"å‰µä½œä¸€é¦–é—œæ–¼å’–å•¡åº—é‚‚é€…çš„çˆµå£«é¢¨æ ¼æ­Œè©\",\n",
    "        \"output\": \"\"\"ğŸµ ã€Šå’–å•¡åº—çš„é‚‚é€…ã€‹\n",
    "\n",
    "[ç¬¬ä¸€æ®µ]\n",
    "Sunday morning coffee shop\n",
    "é™½å…‰é€éç™¾è‘‰çª—\n",
    "ä½ ååœ¨è§’è½çš„ä½ç½®\n",
    "å°ˆæ³¨åœ°çœ‹è‘—æ›¸\n",
    "æ‹¿éµçš„é¦™æ°£ç€°æ¼«\n",
    "æ··åˆè‘—ä½ çš„é¦™æ°´å‘³\n",
    "çˆµå£«æ¨‚è¼•æŸ”åœ°æ’­æ”¾\n",
    "é€™ç•«é¢å¤ªå®Œç¾\n",
    "\n",
    "[å‰¯æ­Œ]\n",
    "Coffee shop romance\n",
    "å’–å•¡åº—è£¡çš„æµªæ¼«\n",
    "Slow jazz and your smile\n",
    "æ…¢çˆµå£«å’Œä½ çš„ç¬‘å®¹\n",
    "This moment feels so right\n",
    "é€™ä¸€åˆ»å¦‚æ­¤ç¾å¥½\n",
    "I want to make you mine\n",
    "æˆ‘æƒ³è®“ä½ å±¬æ–¼æˆ‘\n",
    "\n",
    "[ç¬¬äºŒæ®µ]\n",
    "ä½ æŠ¬é ­çœ‹å‘æˆ‘çš„æ–¹å‘\n",
    "æˆ‘å€‘çš„çœ¼ç¥ç›¸é‡\n",
    "æ™‚é–“å½·å½¿éœæ­¢äº†\n",
    "åªæœ‰å¿ƒè·³çš„ç¯€æ‹\n",
    "æˆ‘èµ°å‘ä½ çš„åº§ä½\n",
    "é¼“èµ·å‹‡æ°£èªªäº†è²Hi\n",
    "ä½ çš„ç¬‘å®¹å¦‚é™½å…‰\n",
    "æº«æš–äº†æ•´å€‹å’–å•¡åº—\n",
    "\n",
    "[æ©‹æ®µ]\n",
    "Maybe this is destiny\n",
    "ä¹Ÿè¨±é€™å°±æ˜¯å‘½é‹\n",
    "Maybe this is love at first sight\n",
    "ä¹Ÿè¨±é€™å°±æ˜¯ä¸€è¦‹é¾æƒ…\n",
    "\n",
    "[çµå°¾]\n",
    "å’–å•¡åº—çš„é‚‚é€…\n",
    "æ˜¯æˆ‘å€‘æ„›æƒ…çš„é–‹å§‹\n",
    "Jazz music plays on\n",
    "çˆµå£«æ¨‚ç¹¼çºŒæ’­æ”¾è‘—\n",
    "But now we have our own song\n",
    "ä½†ç¾åœ¨æˆ‘å€‘æœ‰äº†è‡ªå·±çš„æ­Œ\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"ğŸµ æ­Œè©å‰µä½œæ•¸æ“šæº–å‚™å®Œæˆï¼\")\n",
    "print(f\"ğŸ“Š ç¸½æ¨£æœ¬æ•¸: {len(lyrics_training_data)}\")\n",
    "print(f\"ğŸ¶ æµè¡Œæƒ…æ­Œ: {len([d for d in lyrics_training_data if 'æµè¡Œ' in d['instruction'] or 'æƒ…æ­Œ' in d['instruction'] or 'å¤±æˆ€' in d['instruction'] or 'æ¯è¦ª' in d['instruction']])} é¦–\")\n",
    "print(f\"ğŸ¸ æ–æ»¾å‹µå¿—: {len([d for d in lyrics_training_data if 'æ–æ»¾' in d['instruction'] or 'å‹µå¿—' in d['instruction'] or 'å‰µæ¥­' in d['instruction']])} é¦–\")\n",
    "print(f\"ğŸ¤ æ°‘è¬ æ²»ç™’: {len([d for d in lyrics_training_data if 'æ°‘è¬ ' in d['instruction'] or 'æ²»ç™’' in d['instruction'] or 'å››å­£' in d['instruction']])} é¦–\")\n",
    "print(f\"ğŸµ èªªå”±ç¯€æ‹: {len([d for d in lyrics_training_data if 'èªªå”±' in d['instruction'] or 'rap' in d['instruction'].lower() or 'ç¶²çµ¡' in d['instruction']])} é¦–\")\n",
    "print(f\"ğŸ¼ å¤é¢¨è©©æ„: {len([d for d in lyrics_training_data if 'ä¸­åœ‹é¢¨' in d['instruction'] or 'å¤' in d['instruction'] or 'æ›¸ç”Ÿ' in d['instruction']])} é¦–\")\n",
    "print(f\"ğŸ¹ çˆµå£«æµªæ¼«: {len([d for d in lyrics_training_data if 'çˆµå£«' in d['instruction'] or 'å’–å•¡åº—' in d['instruction']])} é¦–\")\n",
    "\n",
    "# é¡¯ç¤ºä¸€å€‹æ¨£æœ¬\n",
    "print(\"\\nğŸ¼ æ¨£æœ¬é è¦½ - æµè¡Œæƒ…æ­Œ:\")\n",
    "print(\"=\"*60)\n",
    "sample = lyrics_training_data[0]\n",
    "print(f\"æŒ‡ä»¤: {sample['instruction']}\")\n",
    "print(f\"æ­Œè©:\\n{sample['output'][:300]}...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ è¼‰å…¥æ¨¡å‹å’Œåˆ†è©å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹é…ç½®\n",
    "MODEL_NAME = \"google/gemma-2-1b-it\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"ğŸ¼ é–‹å§‹è¼‰å…¥æ­Œè©å‰µä½œæ¨¡å‹: {MODEL_NAME}\")\n",
    "print(f\"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}\")\n",
    "\n",
    "# è¼‰å…¥åˆ†è©å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# è¨­ç½® pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"âœ… åˆ†è©å™¨è¼‰å…¥å®Œæˆï¼Œè©å½™é‡: {len(tokenizer):,}\")\n",
    "\n",
    "# è¼‰å…¥æ¨¡å‹\n",
    "model_kwargs = {\n",
    "    \"trust_remote_code\": True,\n",
    "    \"torch_dtype\": torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    \"device_map\": \"auto\" if device == \"cuda\" else None,\n",
    "    \"use_cache\": False,\n",
    "}\n",
    "\n",
    "# æ™ºèƒ½è¨˜æ†¶é«”ç®¡ç†\n",
    "if device == \"cuda\" and torch.cuda.get_device_properties(0).total_memory < 16 * 1024**3:\n",
    "    print(\"âš¡ å•Ÿç”¨ 8-bit é‡åŒ–ä»¥ç¯€çœè¨˜æ†¶é«”\")\n",
    "    model_kwargs.update({\n",
    "        \"load_in_8bit\": True,\n",
    "        \"llm_int8_threshold\": 6.0,\n",
    "    })\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, **model_kwargs)\n",
    "\n",
    "# æº–å‚™é‡åŒ–è¨“ç·´\n",
    "if \"load_in_8bit\" in model_kwargs:\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼\")\n",
    "print(f\"ğŸ“Š ç¸½åƒæ•¸é‡: {model.num_parameters():,}\")\n",
    "\n",
    "# è¨˜æ†¶é«”å ±å‘Š\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    memory_used = torch.cuda.memory_allocated() / 1024**3\n",
    "    print(f\"ğŸ’¾ ç•¶å‰ GPU è¨˜æ†¶é«”ä½¿ç”¨: {memory_used:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ è¨­ç½®æ­Œè©å‰µä½œå°ˆç”¨ LoRA é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­Œè©å‰µä½œå°ˆç”¨ LoRA é…ç½®\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,  # é©ä¸­çš„ç§©æ•¸ï¼Œå¹³è¡¡å‰µæ„å’Œæ§åˆ¶\n",
    "    lora_alpha=32,  # è¼ƒé«˜çš„ alpha å€¼ï¼Œå¢å¼·å­¸ç¿’æ•ˆæœ\n",
    "    lora_dropout=0.05,  # è¼ƒä½çš„ dropoutï¼Œä¿æŒå‰µæ„æµæš¢æ€§\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # æ³¨æ„åŠ›å±¤\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"      # å‰é¥‹å±¤\n",
    "    ],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# å‰µå»ºæ­Œè©å‰µä½œ PEFT æ¨¡å‹\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "# è¨ˆç®—åƒæ•¸çµ±è¨ˆ\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "\n",
    "print(\"ğŸ¼ æ­Œè©å‰µä½œ LoRA é…ç½®å®Œæˆï¼\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ å°ˆç”¨é…ç½®ç‰¹é»:\")\n",
    "print(f\"   â€¢ ç§©æ•¸ (r): {lora_config.r} - å¹³è¡¡å‰µæ„å’Œæ§åˆ¶\")\n",
    "print(f\"   â€¢ Alpha: {lora_config.lora_alpha} - å¢å¼·å­¸ç¿’æ•ˆæœ\")\n",
    "print(f\"   â€¢ Dropout: {lora_config.lora_dropout} - ä¿æŒå‰µæ„æµæš¢\")\n",
    "print(f\"   â€¢ ç›®æ¨™æ¨¡çµ„: æ³¨æ„åŠ› + å‰é¥‹å±¤\")\n",
    "print(f\"\\nğŸ“Š åƒæ•¸çµ±è¨ˆ:\")\n",
    "print(f\"   â€¢ ç¸½åƒæ•¸: {total_params:,}\")\n",
    "print(f\"   â€¢ å¯è¨“ç·´åƒæ•¸: {trainable_params:,}\")\n",
    "print(f\"   â€¢ å¯è¨“ç·´æ¯”ä¾‹: {100 * trainable_params / total_params:.3f}%\")\n",
    "print(f\"   â€¢ é©é…å™¨å¤§å°: ~{trainable_params * 2 / 1024**2:.1f} MB\")\n",
    "\n",
    "# è©³ç´°åƒæ•¸ä¿¡æ¯\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ æ­Œè©æ•¸æ“šé è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_lyrics_data(data_list):\n",
    "    \"\"\"å°‡æ­Œè©æ•¸æ“šæ ¼å¼åŒ–ç‚º Gemma æŒ‡ä»¤æ ¼å¼\"\"\"\n",
    "    formatted_texts = []\n",
    "    \n",
    "    for item in data_list:\n",
    "        # ä½¿ç”¨ Gemma çš„æŒ‡ä»¤æ ¼å¼ï¼Œå°ˆé–€é‡å°æ­Œè©å‰µä½œ\n",
    "        formatted_text = f\"<bos><start_of_turn>user\\n{item['instruction']}<end_of_turn>\\n<start_of_turn>model\\n{item['output']}<end_of_turn><eos>\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    \n",
    "    return formatted_texts\n",
    "\n",
    "def tokenize_lyrics(examples):\n",
    "    \"\"\"æ­Œè©å°ˆç”¨åˆ†è©å‡½æ•¸\"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=1536,  # æ›´é•·çš„åºåˆ—ä»¥å®¹ç´å®Œæ•´æ­Œè©\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    \n",
    "    # è¨­ç½®æ¨™ç±¤\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# æ ¼å¼åŒ–æ­Œè©æ•¸æ“š\n",
    "formatted_lyrics = format_lyrics_data(lyrics_training_data)\n",
    "\n",
    "# åˆ†å‰²è¨“ç·´å’Œé©—è­‰æ•¸æ“š (85/15ï¼Œæ›´å¤šè¨“ç·´æ•¸æ“š)\n",
    "train_size = int(0.85 * len(formatted_lyrics))\n",
    "train_texts = formatted_lyrics[:train_size]\n",
    "eval_texts = formatted_lyrics[train_size:]\n",
    "\n",
    "print(f\"ğŸµ æ­Œè©æ•¸æ“šé è™•ç†å®Œæˆ\")\n",
    "print(f\"ğŸ“Š è¨“ç·´æ¨£æœ¬: {len(train_texts)} é¦–æ­Œè©\")\n",
    "print(f\"ğŸ“Š é©—è­‰æ¨£æœ¬: {len(eval_texts)} é¦–æ­Œè©\")\n",
    "print(f\"ğŸ“ æœ€å¤§åºåˆ—é•·åº¦: 1536 tokens\")\n",
    "\n",
    "# é¡¯ç¤ºæ ¼å¼åŒ–æ¨£æœ¬\n",
    "print(\"\\nğŸ¼ æ ¼å¼åŒ–æ­Œè©æ¨£æœ¬:\")\n",
    "print(\"=\" * 70)\n",
    "sample_text = train_texts[0]\n",
    "if len(sample_text) > 800:\n",
    "    print(sample_text[:400] + \"\\n...\\n\" + sample_text[-400:])\n",
    "else:\n",
    "    print(sample_text)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# å‰µå»ºæ•¸æ“šé›†\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts})\n",
    "eval_dataset = Dataset.from_dict({\"text\": eval_texts})\n",
    "\n",
    "# åˆ†è©è™•ç†\n",
    "print(\"\\nğŸ”¤ é–‹å§‹æ­Œè©åˆ†è©è™•ç†...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_lyrics,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"åˆ†è©è¨“ç·´æ­Œè©\"\n",
    ")\n",
    "\n",
    "eval_dataset = eval_dataset.map(\n",
    "    tokenize_lyrics,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"åˆ†è©é©—è­‰æ­Œè©\"\n",
    ")\n",
    "\n",
    "print(\"âœ… æ­Œè©æ•¸æ“šé è™•ç†å®Œæˆï¼\")\n",
    "\n",
    "# åˆ†ææ­Œè©é•·åº¦åˆ†ä½ˆ\n",
    "lengths = [len(tokenizer.tokenize(text)) for text in train_texts]\n",
    "avg_length = sum(lengths) / len(lengths)\n",
    "max_length = max(lengths)\n",
    "min_length = min(lengths)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ­Œè©é•·åº¦çµ±è¨ˆ:\")\n",
    "print(f\"   â€¢ å¹³å‡é•·åº¦: {avg_length:.0f} tokens\")\n",
    "print(f\"   â€¢ æœ€é•·æ­Œè©: {max_length} tokens\")\n",
    "print(f\"   â€¢ æœ€çŸ­æ­Œè©: {min_length} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ æ­Œè©å‰µä½œå°ˆç”¨è¨“ç·´é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ™ºèƒ½æ‰¹æ¬¡å¤§å°èª¿æ•´\n",
    "if device == \"cuda\":\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if gpu_memory_gb >= 16:\n",
    "        batch_size = 3\n",
    "        gradient_accumulation_steps = 2\n",
    "    elif gpu_memory_gb >= 8:\n",
    "        batch_size = 2\n",
    "        gradient_accumulation_steps = 3\n",
    "    else:\n",
    "        batch_size = 1\n",
    "        gradient_accumulation_steps = 6\n",
    "else:\n",
    "    batch_size = 1\n",
    "    gradient_accumulation_steps = 6\n",
    "\n",
    "print(f\"ğŸ›ï¸  æ­Œè©è¨“ç·´é…ç½®:\")\n",
    "print(f\"   â€¢ æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
    "print(f\"   â€¢ æ¢¯åº¦ç´¯ç©: {gradient_accumulation_steps} æ­¥\")\n",
    "print(f\"   â€¢ æœ‰æ•ˆæ‰¹æ¬¡: {batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"   â€¢ GPU è¨˜æ†¶é«”: {gpu_memory_gb:.1f} GB\" if device == \"cuda\" else \"   â€¢ ä½¿ç”¨ CPU è¨“ç·´\")\n",
    "\n",
    "# æ­Œè©å‰µä½œå°ˆç”¨è¨“ç·´åƒæ•¸\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lyrics_lora_outputs\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=4,  # æ›´å¤š epochs ä»¥å­¸ç¿’æ­Œè©çµæ§‹\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    warmup_steps=30,  # è¼ƒå°‘é ç†±æ­¥æ•¸\n",
    "    learning_rate=1.5e-4,  # ç¨ä½çš„å­¸ç¿’ç‡ä¿æŒå‰µæ„ç©©å®š\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=3,\n",
    "    save_steps=25,\n",
    "    eval_steps=15,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=None,\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True if device == \"cuda\" else False,\n",
    "    gradient_checkpointing=True,\n",
    "    save_total_limit=3,  # åªä¿ç•™æœ€å¥½çš„ 3 å€‹æª¢æŸ¥é»\n",
    ")\n",
    "\n",
    "# æ­Œè©å°ˆç”¨æ•¸æ“šæ•´ç†å™¨\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "print(\"âœ… æ­Œè©å‰µä½œè¨“ç·´é…ç½®å®Œæˆï¼\")\n",
    "print(f\"ğŸµ å°ˆç”¨é…ç½®ç‰¹é»:\")\n",
    "print(f\"   â€¢ 4 å€‹è¨“ç·´è¼ªæ¬¡ - å……åˆ†å­¸ç¿’æ­Œè©çµæ§‹\")\n",
    "print(f\"   â€¢ å­¸ç¿’ç‡ 1.5e-4 - ç©©å®šçš„å‰µæ„å­¸ç¿’\")\n",
    "print(f\"   â€¢ æ›´é•·åºåˆ—æ”¯æ´ - å®Œæ•´æ­Œè©ç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ é–‹å§‹æ­Œè©å‰µä½œæ¨¡å‹è¨“ç·´ï¼ğŸµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»ºæ­Œè©å‰µä½œå°ˆç”¨è¨“ç·´å™¨\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤ é–‹å§‹æ­Œè©å‰µä½œ AI è¨“ç·´...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸµ è¨“ç·´æ•¸æ“š: {len(train_dataset)} é¦–è±å¯Œæ­Œè©\")\n",
    "print(f\"ğŸ¼ é©—è­‰æ•¸æ“š: {len(eval_dataset)} é¦–æ¸¬è©¦æ­Œè©\")\n",
    "print(f\"ğŸ”„ é è¨ˆè¨“ç·´æ­¥æ•¸: {len(train_dataset) // (batch_size * gradient_accumulation_steps) * 4}\")\n",
    "print(f\"â° é ä¼°æ™‚é–“: 20-40 åˆ†é˜ (ä¾ GPU æ€§èƒ½è€Œå®š)\")\n",
    "print(f\"ğŸ¯ ç›®æ¨™: è¨“ç·´å‡ºå°ˆæ¥­çš„æ­Œè©å‰µä½œ AI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# è¨˜éŒ„è¨“ç·´é–‹å§‹æ™‚é–“\n",
    "start_time = datetime.now()\n",
    "print(f\"ğŸ•’ è¨“ç·´é–‹å§‹æ™‚é–“: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# é–‹å§‹è¨“ç·´\n",
    "trainer.train()\n",
    "\n",
    "# è¨“ç·´å®Œæˆ\n",
    "end_time = datetime.now()\n",
    "training_duration = end_time - start_time\n",
    "\n",
    "print(\"\\nğŸ‰ æ­Œè©å‰µä½œæ¨¡å‹è¨“ç·´å®Œæˆï¼\")\n",
    "print(f\"â±ï¸  ç¸½è¨“ç·´æ™‚é–“: {training_duration}\")\n",
    "print(f\"ğŸ•’ å®Œæˆæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ä¿å­˜æœ€çµ‚æ¨¡å‹\n",
    "print(\"\\nğŸ’¾ ä¿å­˜æ­Œè©å‰µä½œæ¨¡å‹...\")\n",
    "trainer.save_model()\n",
    "lyrics_adapter_path = \"./lyrics_lora_outputs/lyrics_adapter\"\n",
    "peft_model.save_pretrained(lyrics_adapter_path)\n",
    "\n",
    "# ä¿å­˜é…ç½®ä¿¡æ¯\n",
    "config_info = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"task\": \"lyrics_generation\",\n",
    "    \"training_samples\": len(train_dataset),\n",
    "    \"validation_samples\": len(eval_dataset),\n",
    "    \"training_time\": str(training_duration),\n",
    "    \"lora_config\": {\n",
    "        \"r\": lora_config.r,\n",
    "        \"alpha\": lora_config.lora_alpha,\n",
    "        \"dropout\": lora_config.lora_dropout,\n",
    "        \"target_modules\": lora_config.target_modules\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"./lyrics_lora_outputs/training_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_info, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… æ­Œè©å‰µä½œæ¨¡å‹å·²ä¿å­˜è‡³: {lyrics_adapter_path}\")\n",
    "print(f\"ğŸ“‹ è¨“ç·´é…ç½®å·²ä¿å­˜è‡³: ./lyrics_lora_outputs/training_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ æ¸¬è©¦æ­Œè©å‰µä½œæ•ˆæœï¼ğŸ­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(prompt, max_length=400, temperature=0.8):\n",
    "    \"\"\"ç”Ÿæˆæ­Œè©çš„æ ¸å¿ƒå‡½æ•¸\"\"\"\n",
    "    # æ ¼å¼åŒ–è¼¸å…¥\n",
    "    formatted_prompt = f\"<bos><start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    \n",
    "    # åˆ†è©\n",
    "    inputs = tokenizer(\n",
    "        formatted_prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # ç”Ÿæˆæ­Œè©\n",
    "    peft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1,  # æ¸›å°‘é‡è¤‡\n",
    "        )\n",
    "    \n",
    "    # è§£ç¢¼ä¸¦æå–æ­Œè©\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # æå–æ¨¡å‹ç”Ÿæˆçš„éƒ¨åˆ†\n",
    "    if \"<start_of_turn>model\" in generated_text:\n",
    "        lyrics = generated_text.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        if \"<end_of_turn>\" in lyrics:\n",
    "            lyrics = lyrics.split(\"<end_of_turn>\")[0].strip()\n",
    "        return lyrics\n",
    "    else:\n",
    "        return generated_text\n",
    "\n",
    "# å¤šæ¨£åŒ–çš„æ¸¬è©¦ä¸»é¡Œ\n",
    "test_prompts = [\n",
    "    \"ğŸµ å‰µä½œä¸€é¦–é—œæ–¼å®‡å®™æ¢ç´¢çš„ç§‘å¹»é¢¨æ ¼æ­Œè©\",\n",
    "    \"ğŸ¸ å¯«ä¸€é¦–é—œæ–¼ç¨‹å¼è¨­è¨ˆå¸«çš„å¹½é»˜æ–æ»¾æ­Œè©\",\n",
    "    \"ğŸ¤ å‰µä½œä¸€é¦–é—œæ–¼ç«¥å¹´å›æ†¶çš„æº«æš–æ°‘è¬ \",\n",
    "    \"ğŸ¼ å¯«ä¸€é¦–é—œæ–¼å­¸ç¿’AIçš„å‹µå¿—èªªå”±æ­Œè©\",\n",
    "    \"ğŸ¹ å‰µä½œä¸€é¦–é—œæ–¼æ·±å¤œåŠ ç­çš„çˆµå£«é¢¨æ ¼æ­Œè©\",\n",
    "    \"ğŸ¶ å¯«ä¸€é¦–é—œæ–¼ç’°ä¿ä¸»é¡Œçš„æµè¡Œæ­Œè©\"\n",
    "]\n",
    "\n",
    "print(\"ğŸª é–‹å§‹æ¸¬è©¦æ­Œè©å‰µä½œ AI çš„å‰µæ„èƒ½åŠ›...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "generated_lyrics = []  # ä¿å­˜ç”Ÿæˆçš„æ­Œè©ç”¨æ–¼ Gradio\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\nğŸµ æ¸¬è©¦ {i}: {prompt}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    lyrics = generate_lyrics(prompt)\n",
    "    generated_lyrics.append((prompt, lyrics))\n",
    "    \n",
    "    print(f\"ğŸ¼ ç”Ÿæˆæ­Œè©:\\n{lyrics}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if i < len(test_prompts):\n",
    "        print(\"â³ ç”Ÿæˆä¸‹ä¸€é¦–æ­Œè©...\")\n",
    "\n",
    "print(\"\\nğŸŠ æ­Œè©å‰µä½œ AI æ¸¬è©¦å®Œæˆï¼\")\n",
    "print(\"âœ¨ æ‚¨çš„å°ˆå±¬æ­Œè©å‰µä½œ AI å·²ç¶“æº–å‚™å°±ç·’ï¼\")\n",
    "\n",
    "# ç°¡å–®çš„æ­Œè©å“è³ªè©•ä¼°\n",
    "print(\"\\nğŸ“Š æ­Œè©å“è³ªåˆæ­¥è©•ä¼°:\")\n",
    "total_chars = sum(len(lyrics) for _, lyrics in generated_lyrics)\n",
    "avg_length = total_chars / len(generated_lyrics)\n",
    "print(f\"   âœ… å¹³å‡æ­Œè©é•·åº¦: {avg_length:.0f} å­—ç¬¦\")\n",
    "print(f\"   âœ… çµæ§‹å®Œæ•´æ€§: {'è‰¯å¥½' if avg_length > 200 else 'éœ€æ”¹é€²'}\")\n",
    "print(f\"   âœ… å‰µæ„å¤šæ¨£æ€§: {'è±å¯Œ' if len(set(lyrics[:50] for _, lyrics in generated_lyrics)) == len(generated_lyrics) else 'ä¸­ç­‰'}\")\n",
    "print(f\"   âœ… æ ¼å¼è¦ç¯„æ€§: {'ç¬¦åˆ' if all('ğŸµ' in lyrics or '[' in lyrics for _, lyrics in generated_lyrics) else 'éƒ¨åˆ†ç¬¦åˆ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ å‰µå»º Gradio Web UI äº’å‹•ä»‹é¢ ğŸŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_generator_interface(prompt, style, mood, temperature, max_length):\n",
    "    \"\"\"Gradio ä»‹é¢çš„æ­Œè©ç”Ÿæˆå‡½æ•¸\"\"\"\n",
    "    try:\n",
    "        # æ§‹å»ºå®Œæ•´çš„æç¤ºè©\n",
    "        if style != \"ä¸æŒ‡å®š\" and mood != \"ä¸æŒ‡å®š\":\n",
    "            full_prompt = f\"å‰µä½œä¸€é¦–{style}é¢¨æ ¼çš„{mood}æ­Œè©ï¼Œä¸»é¡Œæ˜¯ï¼š{prompt}\"\n",
    "        elif style != \"ä¸æŒ‡å®š\":\n",
    "            full_prompt = f\"å‰µä½œä¸€é¦–{style}é¢¨æ ¼çš„æ­Œè©ï¼Œä¸»é¡Œæ˜¯ï¼š{prompt}\"\n",
    "        elif mood != \"ä¸æŒ‡å®š\":\n",
    "            full_prompt = f\"å‰µä½œä¸€é¦–{mood}æ­Œè©ï¼Œä¸»é¡Œæ˜¯ï¼š{prompt}\"\n",
    "        else:\n",
    "            full_prompt = f\"å‰µä½œä¸€é¦–æ­Œè©ï¼Œä¸»é¡Œæ˜¯ï¼š{prompt}\"\n",
    "        \n",
    "        # ç”Ÿæˆæ­Œè©\n",
    "        lyrics = generate_lyrics(\n",
    "            full_prompt, \n",
    "            max_length=int(max_length), \n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # æ·»åŠ ç”Ÿæˆä¿¡æ¯\n",
    "        generation_info = f\"\\n\\n--- ç”Ÿæˆä¿¡æ¯ ---\\né¢¨æ ¼: {style}\\næƒ…æ„Ÿ: {mood}\\næº«åº¦: {temperature}\\næœ€å¤§é•·åº¦: {max_length}\"\n",
    "        \n",
    "        return lyrics + generation_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"ç”Ÿæˆæ­Œè©æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\\nè«‹å˜—è©¦èª¿æ•´åƒæ•¸æˆ–é‡æ–°è¼¸å…¥ä¸»é¡Œã€‚\"\n",
    "\n",
    "def get_random_prompt():\n",
    "    \"\"\"ç²å–éš¨æ©Ÿæ­Œè©ä¸»é¡Œ\"\"\"\n",
    "    random_prompts = [\n",
    "        \"åˆå¤œçš„å’–å•¡åº—\",\n",
    "        \"è¿½é€å¤¢æƒ³çš„å¹´è¼•äºº\", \n",
    "        \"ä¸‹é›¨å¤©çš„å›æ†¶\",\n",
    "        \"åŸå¸‚çš„éœ“è™¹ç‡ˆ\",\n",
    "        \"è€æœ‹å‹çš„é‡é€¢\",\n",
    "        \"æ˜Ÿç©ºä¸‹çš„è¨±é¡˜\",\n",
    "        \"ç•¢æ¥­å­£çš„é›¢åˆ¥\",\n",
    "        \"ç¬¬ä¸€æ¬¡æˆ€æ„›\",\n",
    "        \"å®¶é„‰çš„å‘³é“\",\n",
    "        \"å…‹æœå›°é›£çš„å‹‡æ°£\"\n",
    "    ]\n",
    "    import random\n",
    "    return random.choice(random_prompts)\n",
    "\n",
    "# å‰µå»º Gradio ä»‹é¢\n",
    "print(\"ğŸŒ å‰µå»ºæ­Œè©å‰µä½œ Web UI...\")\n",
    "\n",
    "# å®šç¾©ä»‹é¢çµ„ä»¶\n",
    "with gr.Blocks(title=\"ğŸµ AI æ­Œè©å‰µä½œå¤§å¸«\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # ğŸµ AI æ­Œè©å‰µä½œå¤§å¸«\n",
    "        \n",
    "        ä½¿ç”¨ LoRA å¾®èª¿çš„ Gemma-2-1B-IT æ¨¡å‹ï¼Œç‚ºæ‚¨å‰µä½œå„ç¨®é¢¨æ ¼çš„åŸå‰µæ­Œè©ï¼\n",
    "        æ”¯æ´å¤šç¨®éŸ³æ¨‚é¢¨æ ¼å’Œæƒ…æ„Ÿè¡¨é”ï¼Œè®“å‰µæ„ç„¡é™å»¶ä¼¸ã€‚\n",
    "        \n",
    "        âœ¨ **ç‰¹è‰²åŠŸèƒ½**:\n",
    "        - ğŸ¶ å¤šç¨®éŸ³æ¨‚é¢¨æ ¼ (æµè¡Œã€æ–æ»¾ã€æ°‘è¬ ã€èªªå”±ã€å¤é¢¨ã€çˆµå£«)\n",
    "        - ğŸ’ è±å¯Œæƒ…æ„Ÿè¡¨é” (æµªæ¼«ã€å‹µå¿—ã€æ²»ç™’ã€æ‡·èˆŠç­‰)\n",
    "        - ğŸ›ï¸ å¯èª¿ç¯€å‰µæ„åƒæ•¸\n",
    "        - ğŸ² éš¨æ©Ÿä¸»é¡Œéˆæ„Ÿ\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            # ä¸»è¦è¼¸å…¥å€åŸŸ\n",
    "            prompt_input = gr.Textbox(\n",
    "                label=\"ğŸ¼ æ­Œè©ä¸»é¡Œ\",\n",
    "                placeholder=\"è¼¸å…¥æ‚¨æƒ³è¦çš„æ­Œè©ä¸»é¡Œï¼Œä¾‹å¦‚ï¼š'é—œæ–¼å‹æƒ…çš„æ•…äº‹'ã€'å¤±æˆ€å¾Œçš„æˆé•·'ç­‰\",\n",
    "                lines=2,\n",
    "                value=\"\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                style_dropdown = gr.Dropdown(\n",
    "                    choices=[\"ä¸æŒ‡å®š\", \"æµè¡Œæƒ…æ­Œ\", \"æ–æ»¾å‹µå¿—\", \"æ°‘è¬ æ²»ç™’\", \"èªªå”±ç¯€æ‹\", \"å¤é¢¨è©©æ„\", \"çˆµå£«æµªæ¼«\"],\n",
    "                    label=\"ğŸ¸ éŸ³æ¨‚é¢¨æ ¼\",\n",
    "                    value=\"ä¸æŒ‡å®š\"\n",
    "                )\n",
    "                \n",
    "                mood_dropdown = gr.Dropdown(\n",
    "                    choices=[\"ä¸æŒ‡å®š\", \"æµªæ¼«æº«æŸ”\", \"å‹µå¿—å‘ä¸Š\", \"æ‡·èˆŠæ„Ÿå‚·\", \"æ²»ç™’æº«æš–\", \"æ¿€æ˜‚ç†±è¡€\", \"è©©æ„å„ªç¾\"],\n",
    "                    label=\"ğŸ’ æƒ…æ„Ÿæ°›åœ\", \n",
    "                    value=\"ä¸æŒ‡å®š\"\n",
    "                )\n",
    "            \n",
    "            # é«˜ç´šè¨­å®š\n",
    "            with gr.Accordion(\"ğŸ›ï¸ é«˜ç´šè¨­å®š\", open=False):\n",
    "                temperature_slider = gr.Slider(\n",
    "                    minimum=0.3,\n",
    "                    maximum=1.2, \n",
    "                    value=0.8,\n",
    "                    step=0.1,\n",
    "                    label=\"ğŸŒ¡ï¸ å‰µæ„æº«åº¦ (è¶Šé«˜è¶Šæœ‰å‰µæ„)\"\n",
    "                )\n",
    "                \n",
    "                max_length_slider = gr.Slider(\n",
    "                    minimum=200,\n",
    "                    maximum=600,\n",
    "                    value=400,\n",
    "                    step=50,\n",
    "                    label=\"ğŸ“ æœ€å¤§é•·åº¦ (å­—ç¬¦æ•¸)\"\n",
    "                )\n",
    "            \n",
    "            # æŒ‰éˆ•å€åŸŸ\n",
    "            with gr.Row():\n",
    "                generate_btn = gr.Button(\n",
    "                    \"ğŸµ å‰µä½œæ­Œè©\", \n",
    "                    variant=\"primary\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "                \n",
    "                random_btn = gr.Button(\n",
    "                    \"ğŸ² éš¨æ©Ÿä¸»é¡Œ\",\n",
    "                    size=\"lg\"\n",
    "                )\n",
    "        \n",
    "        with gr.Column(scale=3):\n",
    "            # è¼¸å‡ºå€åŸŸ\n",
    "            output_text = gr.Textbox(\n",
    "                label=\"ğŸ¼ ç”Ÿæˆçš„æ­Œè©\",\n",
    "                lines=20,\n",
    "                max_lines=25,\n",
    "                show_copy_button=True,\n",
    "                container=True\n",
    "            )\n",
    "    \n",
    "    # ç¯„ä¾‹å±•ç¤º\n",
    "    with gr.Accordion(\"ğŸ“– ä½¿ç”¨ç¯„ä¾‹\", open=False):\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                [\"æ·±å¤œçš„ç¨‹å¼è¨­è¨ˆå¸«\", \"æ–æ»¾å‹µå¿—\", \"æ¿€æ˜‚ç†±è¡€\", 0.8, 400],\n",
    "                [\"æ«»èŠ±é£›èˆçš„æ˜¥å¤©\", \"å¤é¢¨è©©æ„\", \"è©©æ„å„ªç¾\", 0.7, 350],\n",
    "                [\"å’–å•¡åº—çš„é‚‚é€…\", \"çˆµå£«æµªæ¼«\", \"æµªæ¼«æº«æŸ”\", 0.9, 300],\n",
    "                [\"ç«¥å¹´çš„å¤å¤©\", \"æ°‘è¬ æ²»ç™’\", \"æ‡·èˆŠæ„Ÿå‚·\", 0.6, 400],\n",
    "                [\"å‰µæ¥­è·¯ä¸Šçš„å¥®é¬¥\", \"èªªå”±ç¯€æ‹\", \"å‹µå¿—å‘ä¸Š\", 1.0, 450],\n",
    "                [\"æ¯è¦ªçš„æº«æš–æ‡·æŠ±\", \"æµè¡Œæƒ…æ­Œ\", \"æ²»ç™’æº«æš–\", 0.7, 350]\n",
    "            ],\n",
    "            inputs=[prompt_input, style_dropdown, mood_dropdown, temperature_slider, max_length_slider]\n",
    "        )\n",
    "    \n",
    "    # ç‰ˆæ¬Šè³‡è¨Š\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        ---\n",
    "        ğŸ’¡ **ä½¿ç”¨æç¤º**: \n",
    "        - å˜—è©¦ä¸åŒçš„é¢¨æ ¼å’Œæƒ…æ„Ÿçµ„åˆ\n",
    "        - èª¿æ•´å‰µæ„æº«åº¦å¯ä»¥æ”¹è®Šæ­Œè©çš„å‰µæ–°ç¨‹åº¦\n",
    "        - ä½¿ç”¨å…·é«”è€Œæœ‰ç•«é¢æ„Ÿçš„ä¸»é¡Œèƒ½ç”¢ç”Ÿæ›´å¥½çš„æ•ˆæœ\n",
    "        \n",
    "        ğŸ¤– **æŠ€è¡“æ”¯æ´**: LoRA å¾®èª¿ + Gemma-2-1B-IT | ğŸµ **æ­Œè©ç´ æ**: 20+ å¤šé¢¨æ ¼åŸå‰µè¨“ç·´æ¨£æœ¬\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # ç¶å®šäº‹ä»¶\n",
    "    generate_btn.click(\n",
    "        fn=lyrics_generator_interface,\n",
    "        inputs=[prompt_input, style_dropdown, mood_dropdown, temperature_slider, max_length_slider],\n",
    "        outputs=output_text,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    random_btn.click(\n",
    "        fn=get_random_prompt,\n",
    "        outputs=prompt_input,\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "print(\"âœ… Gradio Web UI å‰µå»ºå®Œæˆï¼\")\n",
    "\n",
    "# å•Ÿå‹•ä»‹é¢\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nğŸš€ å•Ÿå‹•æ­Œè©å‰µä½œ Web ä»‹é¢...\")\n",
    "    print(\"ğŸŒ ä»‹é¢å°‡åœ¨æ–°è¦–çª—ä¸­é–‹å•Ÿ\")\n",
    "    print(\"ğŸ“± æ”¯æ´é›»è…¦å’Œæ‰‹æ©Ÿè¨ªå•\")\n",
    "    print(\"âš¡ å³æ™‚ç”Ÿæˆï¼Œå¿«é€Ÿå›æ‡‰\")\n",
    "    \n",
    "    demo.launch(\n",
    "        share=True,  # å‰µå»ºå…¬é–‹åˆ†äº«é€£çµ\n",
    "        server_name=\"0.0.0.0\",  # å…è¨±å¤–éƒ¨è¨ªå•\n",
    "        server_port=7860,  # æŒ‡å®šç«¯å£\n",
    "        show_error=True,\n",
    "        quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ è¨“ç·´æˆæœåˆ†æèˆ‡ç¸½çµ ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´æˆæœåˆ†æ\n",
    "print(\"ğŸ“ˆ æ­Œè©å‰µä½œ AI è¨“ç·´æˆæœåˆ†æ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if trainer.state.log_history:\n",
    "    # æå–è¨“ç·´æ­·å²\n",
    "    train_losses = [log.get(\"train_loss\") for log in trainer.state.log_history if \"train_loss\" in log]\n",
    "    eval_losses = [log.get(\"eval_loss\") for log in trainer.state.log_history if \"eval_loss\" in log]\n",
    "    learning_rates = [log.get(\"learning_rate\") for log in trainer.state.log_history if \"learning_rate\" in log]\n",
    "    \n",
    "    if train_losses:\n",
    "        print(f\"ğŸ¯ è¨“ç·´æ•ˆæœåˆ†æ:\")\n",
    "        print(f\"   â€¢ åˆå§‹è¨“ç·´æå¤±: {train_losses[0]:.4f}\")\n",
    "        print(f\"   â€¢ æœ€çµ‚è¨“ç·´æå¤±: {train_losses[-1]:.4f}\")\n",
    "        improvement = (train_losses[0] - train_losses[-1]) / train_losses[0] * 100\n",
    "        print(f\"   â€¢ æå¤±æ”¹å–„ç¨‹åº¦: {improvement:.1f}%\")\n",
    "        print(f\"   â€¢ æ”¶æ–‚ç‹€æ…‹: {'è‰¯å¥½' if improvement > 10 else 'éœ€è¦æ›´å¤šè¨“ç·´'}\")\n",
    "    \n",
    "    if eval_losses:\n",
    "        best_eval_loss = min(eval_losses)\n",
    "        print(f\"\\nğŸ“Š é©—è­‰æ•ˆæœåˆ†æ:\")\n",
    "        print(f\"   â€¢ æœ€ä½³é©—è­‰æå¤±: {best_eval_loss:.4f}\")\n",
    "        print(f\"   â€¢ éæ“¬åˆæª¢æ¸¬: {'æœªéæ“¬åˆ' if best_eval_loss < train_losses[-1] * 1.2 else 'è¼•å¾®éæ“¬åˆ'}\")\n",
    "\n",
    "# æ¨¡å‹æ•ˆèƒ½åˆ†æ\n",
    "print(f\"\\nâš¡ æ¨¡å‹æ•ˆèƒ½åˆ†æ:\")\n",
    "print(f\"   â€¢ LoRA åƒæ•¸æ•ˆç‡: {100 * trainable_params / total_params:.3f}%\")\n",
    "print(f\"   â€¢ é©é…å™¨å¤§å°: ~{trainable_params * 2 / 1024**2:.1f} MB\")\n",
    "print(f\"   â€¢ ç¸½è¨“ç·´æ™‚é–“: {training_duration}\")\n",
    "print(f\"   â€¢ æ¯é¦–æ­Œè©è¨“ç·´æ™‚é–“: ~{training_duration.total_seconds() / len(train_dataset):.1f} ç§’\")\n",
    "\n",
    "# GPU è¨˜æ†¶é«”åˆ†æ\n",
    "if device == \"cuda\":\n",
    "    max_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "    current_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    print(f\"\\nğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨åˆ†æ:\")\n",
    "    print(f\"   â€¢ å³°å€¼ GPU è¨˜æ†¶é«”: {max_memory:.1f} GB\")\n",
    "    print(f\"   â€¢ ç•¶å‰ GPU è¨˜æ†¶é«”: {current_memory:.1f} GB\")\n",
    "    print(f\"   â€¢ è¨˜æ†¶é«”æ•ˆç‡: {'å„ªç§€' if max_memory < 8 else 'è‰¯å¥½' if max_memory < 12 else 'ä¸€èˆ¬'}\")\n",
    "\n",
    "# æ­Œè©å‰µä½œå“è³ªè©•ä¼°\n",
    "print(f\"\\nğŸ¼ æ­Œè©å‰µä½œå“è³ªè©•ä¼°:\")\n",
    "if generated_lyrics:\n",
    "    # åˆ†æç”Ÿæˆæ­Œè©çš„ç‰¹å¾\n",
    "    total_words = sum(len(lyrics.split()) for _, lyrics in generated_lyrics)\n",
    "    avg_words = total_words / len(generated_lyrics)\n",
    "    \n",
    "    structure_count = sum(1 for _, lyrics in generated_lyrics if '[' in lyrics and ']' in lyrics)\n",
    "    emoji_count = sum(1 for _, lyrics in generated_lyrics if 'ğŸµ' in lyrics or 'ğŸ¶' in lyrics)\n",
    "    \n",
    "    print(f\"   â€¢ å¹³å‡æ­Œè©é•·åº¦: {avg_words:.0f} å­—\")\n",
    "    print(f\"   â€¢ çµæ§‹å®Œæ•´æ€§: {structure_count}/{len(generated_lyrics)} é¦–æœ‰å®Œæ•´çµæ§‹\")\n",
    "    print(f\"   â€¢ æ ¼å¼è¦ç¯„æ€§: {emoji_count}/{len(generated_lyrics)} é¦–æœ‰éŸ³ç¬¦ç¬¦è™Ÿ\")\n",
    "    print(f\"   â€¢ å‰µæ„å¤šæ¨£æ€§: {'è±å¯Œ' if len(set(lyrics[:30] for _, lyrics in generated_lyrics)) == len(generated_lyrics) else 'ä¸­ç­‰'}\")\n",
    "    \n",
    "    quality_score = (structure_count + emoji_count) / (2 * len(generated_lyrics)) * 100\n",
    "    print(f\"   â€¢ æ•´é«”å“è³ªè©•åˆ†: {quality_score:.0f}/100\")\n",
    "\n",
    "# ä½¿ç”¨å»ºè­°\n",
    "print(f\"\\nğŸ’¡ ä½¿ç”¨å»ºè­°èˆ‡å„ªåŒ–æ–¹å‘:\")\n",
    "print(f\"   âœ… æ¨¡å‹å·²æˆåŠŸå­¸ç¿’æ­Œè©å‰µä½œçš„åŸºæœ¬çµæ§‹\")\n",
    "print(f\"   âœ… æ”¯æ´å¤šç¨®é¢¨æ ¼çš„æ­Œè©ç”Ÿæˆ\")\n",
    "print(f\"   âœ… Gradio Web UI æä¾›å‹å¥½çš„ä½¿ç”¨ä»‹é¢\")\n",
    "print(f\"\\nğŸ¯ é€²ä¸€æ­¥å„ªåŒ–å»ºè­°:\")\n",
    "print(f\"   â€¢ å¢åŠ æ›´å¤šç‰¹å®šé¢¨æ ¼çš„è¨“ç·´æ•¸æ“š\")\n",
    "print(f\"   â€¢ èª¿æ•´ LoRA åƒæ•¸ä»¥æé«˜ç‰¹å®šé¢¨æ ¼çš„è¡¨ç¾\")\n",
    "print(f\"   â€¢ æ·»åŠ æ­Œè©å“è³ªè©•ä¼°å’Œå¾Œè™•ç†åŠŸèƒ½\")\n",
    "\n",
    "# æˆåŠŸç¸½çµ\n",
    "print(f\"\\nğŸŠ æ­Œè©å‰µä½œ AI é …ç›®æˆåŠŸå®Œæˆï¼\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸµ æ‚¨ç¾åœ¨æ“æœ‰ä¸€å€‹å°ˆæ¥­çš„æ­Œè©å‰µä½œ AI åŠ©æ‰‹\")\n",
    "print(f\"ğŸŒ å¯é€šé Gradio Web UI è¼•é¬†ä½¿ç”¨\")\n",
    "print(f\"âš¡ æ”¯æ´å¯¦æ™‚ç”Ÿæˆï¼Œå¤šé¢¨æ ¼å‰µä½œ\")\n",
    "print(f\"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼Œå¯éš¨æ™‚é‡æ–°è¼‰å…¥ä½¿ç”¨\")\n",
    "print(f\"\\nğŸš€ é–‹å§‹æ‚¨çš„éŸ³æ¨‚å‰µä½œä¹‹æ—…å§ï¼\")\n",
    "\n",
    "# æœ€çµ‚çš„ä½¿ç”¨èªªæ˜\n",
    "print(f\"\\nğŸ“‹ ä½¿ç”¨èªªæ˜:\")\n",
    "print(f\"   1. ğŸŒ é€šéä¸Šæ–¹çš„ Gradio ä»‹é¢é€²è¡Œæ­Œè©å‰µä½œ\")\n",
    "print(f\"   2. ğŸ¯ è¼¸å…¥å…·é«”çš„æ­Œè©ä¸»é¡Œæˆ–éˆæ„Ÿ\")\n",
    "print(f\"   3. ğŸ¸ é¸æ“‡åˆé©çš„éŸ³æ¨‚é¢¨æ ¼å’Œæƒ…æ„Ÿæ°›åœ\")\n",
    "print(f\"   4. ğŸ›ï¸ èª¿æ•´å‰µæ„åƒæ•¸ä»¥ç²å¾—ä¸åŒæ•ˆæœ\")\n",
    "print(f\"   5. ğŸµ é»æ“Šç”ŸæˆæŒ‰éˆ•ï¼Œäº«å— AI å‰µä½œçš„æ­Œè©\")\n",
    "print(f\"\\nğŸ é¡å¤–åŠŸèƒ½:\")\n",
    "print(f\"   â€¢ ğŸ² éš¨æ©Ÿä¸»é¡ŒæŒ‰éˆ•ç²å–å‰µä½œéˆæ„Ÿ\")\n",
    "print(f\"   â€¢ ğŸ“– ç¯„ä¾‹å±•ç¤ºå­¸ç¿’ä½¿ç”¨æ–¹æ³•\")\n",
    "print(f\"   â€¢ ğŸ“‹ ä¸€éµè¤‡è£½ç”Ÿæˆçš„æ­Œè©\")\n",
    "print(f\"   â€¢ ğŸŒ æ”¯æ´æ‰‹æ©Ÿå’Œé›»è…¦è¨ªå•\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lora-fine-tuning-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
